{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e73d0c6",
   "metadata": {},
   "source": [
    "# . Data Cleaning and Merging\n",
    "## Overview\n",
    "This notebook integrates our News Frequency data with three external indicators:\n",
    "1.  **Military Power:** Sourced from Global Firepower (2017-2025).\n",
    "2.  **GDP (Economic Power):** Sourced from the World Bank (Avg 2011-2020).\n",
    "3.  **Democracy Index:** Sourced from the EIU.\n",
    "4.  **Fragile States Index:** Sourced from Fragile States Index\n",
    "\n",
    "## Key Challenges\n",
    "* **Inconsistent Naming:** Handling variations like \"Turkey\" vs. \"Türkiye\" and \"Ivory Coast\" vs. \"Côte d'Ivoire\".\n",
    "* **Missing Military Data:** Entities like **Hong Kong** and **Palestine** appear frequently in news but lack official military rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a4989",
   "metadata": {},
   "source": [
    "### Processing GDP and Democracy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aec553",
   "metadata": {},
   "source": [
    "Here is the code that calculates the averages of GDP's(last 10 years) and Democracy(all available years) scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8185f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mstf\\AppData\\Local\\Temp\\ipykernel_22096\\2476430426.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  gdp_averages = df_countries_gdp.groupby('Entity').apply(gdp_last_10_average).reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Defined set of regional/aggregate names to exclude\n",
    "EXCLUDED_ENTITIES = {\n",
    "    'World', 'Africa', 'Asia', 'Europe', 'Americas', 'North America', \n",
    "    'South America', 'Oceania', 'European Union', 'European Union (27)', \n",
    "    'Middle East and North Africa', 'High-income countries', \n",
    "    'Low-income countries', 'Lower-middle-income countries', \n",
    "    'Upper-middle-income countries', 'East Asia & Pacific (IDA & IBRD countries)', \n",
    "    'Latin America & Caribbean (IDA & IBRD countries)', \n",
    "    'Sub-Saharan Africa (IDA & IBRD countries)', 'OECD members', \n",
    "    'Non-OECD members', 'IDA countries', 'IBRD countries', \n",
    "    'Arab World', 'Central Europe and the Baltics', 'East Asia & Pacific', \n",
    "    'Europe & Central Asia', 'Euro area', 'Fragile and conflict affected situations', \n",
    "    'Heavily indebted poor countries (HIPC)', 'Least developed countries: UN classification',\n",
    "    'Middle East & North Africa', 'North America', 'Other small states', \n",
    "    'Pacific island small states', 'Post-demographic dividend', 'Pre-demographic dividend',\n",
    "    'Small states', 'South Asia', 'Sub-Saharan Africa', \n",
    "    'Upper middle income', 'Upper-middle-income countries', 'Least developed countries',\n",
    "    'East Asia and Pacific (WB)', 'Europe and Central Asia (WB)', \n",
    "    'Latin America and Caribbean (WB)', \n",
    "    'Middle East, North Africa, Afghanistan and Pakistan (WB)', \n",
    "    'North America (WB)', 'South Asia (WB)', 'Sub-Saharan Africa (WB)'\n",
    "}\n",
    "\n",
    "# --- 1) Democracy Averages (Rounded to 2 decimal places) ---\n",
    "df_democracy = pd.read_csv('democracy-index-eiu.csv')\n",
    "\n",
    "# Filter out regions\n",
    "df_countries_democracy = df_democracy[~df_democracy['Entity'].isin(EXCLUDED_ENTITIES)]\n",
    "\n",
    "# Calculate the mean Democracy score\n",
    "democracy_averages = df_countries_democracy.groupby('Entity')['Democracy score'].mean().reset_index()\n",
    "democracy_averages.columns = ['Country', 'Average_Democracy_Score']\n",
    "\n",
    "# Round the score to two digits after the dot\n",
    "democracy_averages['Average_Democracy_Score'] = democracy_averages['Average_Democracy_Score'].round(2)\n",
    "\n",
    "# Sort and save the result\n",
    "democracy_averages = democracy_averages.sort_values(by='Average_Democracy_Score', ascending=False)\n",
    "democracy_averages.to_csv('country_democracy_averages_rounded.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 2) GDP Average for Last 10 Available Years (Convert to Billions, round to 2 decimal places) ---\n",
    "df_gdp = pd.read_csv('GDP_our_world_in_data.csv')\n",
    "\n",
    "# Filter out regions\n",
    "df_countries_gdp = df_gdp[~df_gdp['Entity'].isin(EXCLUDED_ENTITIES)]\n",
    "\n",
    "# Define the function to get the GDP average for the last 10 years\n",
    "def gdp_last_10_average(group):\n",
    "    \"\"\"Sorts data by year and returns the mean GDP of the last 10 available years.\"\"\"\n",
    "    # Sort by year in descending order\n",
    "    group_sorted = group.sort_values(by='Year', ascending=False)\n",
    "    # Take the top 10 available rows and calculate the mean of ny_gdp_mktp_kd\n",
    "    return group_sorted.head(10)['ny_gdp_mktp_kd'].mean()\n",
    "\n",
    "# Group by Entity and apply the custom function\n",
    "gdp_averages = df_countries_gdp.groupby('Entity').apply(gdp_last_10_average).reset_index()\n",
    "gdp_averages.columns = ['Country', 'Average_GDP_Last_10_Years_Raw']\n",
    "\n",
    "# Convert the raw GDP value to Billions of USD (divide by 10^9) and round to 2 decimal places\n",
    "gdp_averages['Average_GDP_Last_10_Years_Billion_USD'] = (\n",
    "    gdp_averages['Average_GDP_Last_10_Years_Raw'] / 1e9\n",
    ").round(2)\n",
    "\n",
    "# Drop the raw value column\n",
    "gdp_averages = gdp_averages.drop(columns=['Average_GDP_Last_10_Years_Raw'])\n",
    "\n",
    "# Sort and save the result\n",
    "gdp_averages = gdp_averages.sort_values(by='Average_GDP_Last_10_Years_Billion_USD', ascending=False)\n",
    "gdp_averages.to_csv('country_gdp_last_10_averages_billions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791fbed",
   "metadata": {},
   "source": [
    "Here, some mismatching countries between two datasets either inputed with guessed value or dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f769dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputation complete.\n",
      "The final Democracy Averages (Imputed) are saved to: country_democracy_averages_imputed.csv\n",
      "The final GDP Averages (Imputed) are saved to: country_gdp_averages_imputed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the previously calculated average files\n",
    "df_democracy_avg = pd.read_csv('country_democracy_averages_rounded.csv')\n",
    "df_gdp_avg = pd.read_csv('country_gdp_last_10_averages_billions.csv')\n",
    "\n",
    "# --- 1. Imputation Data ---\n",
    "# Note: These values are based on reasoned guessing using external context.\n",
    "\n",
    "imputed_democracy_data = pd.DataFrame({\n",
    "    'Country': ['Brunei', 'Kosovo', 'South Sudan', 'Somalia'],\n",
    "    'Average_Democracy_Score': [2.00, 5.50, 1.50, 1.00]\n",
    "})\n",
    "\n",
    "imputed_gdp_data = pd.DataFrame({\n",
    "    'Country': ['North Korea', 'Taiwan', 'Venezuela'],\n",
    "    'Average_GDP_Last_10_Years_Billion_USD': [40.00, 700.00, 150.00]\n",
    "})\n",
    "\n",
    "# --- 2. Merge and Finalize Imputed Democracy Data ---\n",
    "# Concatenate the new data and remove duplicates (keeping the imputed row where country names matched the previous missing list)\n",
    "df_democracy_imputed = pd.concat([df_democracy_avg, imputed_democracy_data], ignore_index=True)\n",
    "\n",
    "# Drop duplicates that may occur if the imputed countries existed in the raw data but were filtered out previously\n",
    "df_democracy_imputed = df_democracy_imputed.drop_duplicates(subset=['Country'], keep='last')\n",
    "\n",
    "# Sort the final list\n",
    "df_democracy_imputed = df_democracy_imputed.sort_values(by='Average_Democracy_Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Save the final imputed list\n",
    "df_democracy_imputed.to_csv('country_democracy_averages_imputed.csv', index=False)\n",
    "\n",
    "\n",
    "# --- 3. Merge and Finalize Imputed GDP Data ---\n",
    "# Concatenate the new data\n",
    "df_gdp_imputed = pd.concat([df_gdp_avg, imputed_gdp_data], ignore_index=True)\n",
    "\n",
    "# Drop duplicates (same rationale as above)\n",
    "df_gdp_imputed = df_gdp_imputed.drop_duplicates(subset=['Country'], keep='last')\n",
    "\n",
    "# Sort the final list\n",
    "df_gdp_imputed = df_gdp_imputed.sort_values(by='Average_GDP_Last_10_Years_Billion_USD', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Save the final imputed list\n",
    "df_gdp_imputed.to_csv('country_gdp_averages_imputed.csv', index=False)\n",
    "\n",
    "print(\"\\nImputation complete.\")\n",
    "print(\"The final Democracy Averages (Imputed) are saved to: country_democracy_averages_imputed.csv\")\n",
    "print(\"The final GDP Averages (Imputed) are saved to: country_gdp_averages_imputed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9e3dbb",
   "metadata": {},
   "source": [
    "### Processing Military Data\n",
    "We create a **\"PowerIndex\"** by averaging historical rankings.\n",
    "* **Metric:** PwrIndx (0.00 is perfect score).\n",
    "* **Inversion:** For analysis, we will later invert this score so that *higher values = stronger military*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fa6f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created 'country_average_power_index.csv'\n",
      "     Country  PowerIndex\n",
      "134  Türkiye        0.21\n",
      "       Country  PowerIndex\n",
      "0  Afghanistan        2.21\n",
      "1      Albania        2.16\n",
      "2      Algeria        0.43\n",
      "3       Angola        0.93\n",
      "4    Argentina        0.56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def process_military_data():\n",
    "    # Get all military csv files\n",
    "    files = glob.glob('*_military.csv')\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    # Standardize column names across different years\n",
    "    col_map = {\n",
    "        'name': 'Country',\n",
    "        'COUNTRY': 'Country',\n",
    "        'country': 'Country',\n",
    "        '2020 ranking': 'Country',\n",
    "        'power_index': 'PowerIndex',\n",
    "        'POWER INDEX': 'PowerIndex',\n",
    "        'pwr_index': 'PowerIndex',\n",
    "        'Unnamed: 1': 'PowerIndex'\n",
    "    }\n",
    "    \n",
    "    for file in files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "            # Normalize column names\n",
    "            df = df.rename(columns=col_map)\n",
    "            \n",
    "            # Check for required columns\n",
    "            if 'Country' in df.columns and 'PowerIndex' in df.columns:\n",
    "                subset = df[['Country', 'PowerIndex']].copy()\n",
    "                \n",
    "                # Convert to numeric, handle errors\n",
    "                subset['PowerIndex'] = pd.to_numeric(subset['PowerIndex'], errors='coerce')\n",
    "                subset = subset.dropna(subset=['PowerIndex'])\n",
    "                \n",
    "                # Clean country names\n",
    "                subset['Country'] = subset['Country'].astype(str).str.strip()\n",
    "                \n",
    "                # --- FIX 1: Combine \"Turkey\" and \"Türkiye\" ---\n",
    "                subset['Country'] = subset['Country'].replace({\n",
    "                    'Turkey': 'Türkiye',\n",
    "                    'Turkiye': 'Türkiye'\n",
    "                })\n",
    "                \n",
    "                dfs.append(subset)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "    \n",
    "    if dfs:\n",
    "        # Combine all data\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "        # Calculate Average\n",
    "        result = combined_df.groupby('Country')['PowerIndex'].mean().reset_index()\n",
    "        \n",
    "        # --- FIX 2: Round to 2 decimal places ---\n",
    "        result['PowerIndex'] = result['PowerIndex'].round(2)\n",
    "        \n",
    "        # Save to CSV\n",
    "        output_filename = 'country_average_power_index.csv'\n",
    "        result.to_csv(output_filename, index=False)\n",
    "        \n",
    "        print(f\"Successfully created '{output_filename}'\")\n",
    "        print(result[result['Country'] == 'Türkiye'])  # Verify the fix\n",
    "        print(result.head())\n",
    "    else:\n",
    "        print(\"No data found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_military_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1355bbc1",
   "metadata": {},
   "source": [
    "### Processing Fragile States Index Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9d3192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 files. Processing...\n",
      "  - Processed: Rankings_2015.csv (Using column: '2015')\n",
      "  - Processed: Rankings_2016.csv (Using column: '2016')\n",
      "  - Processed: Rankings_2017.csv (Using column: '2017')\n",
      "  - Processed: Rankings_2018.csv (Using column: '2018')\n",
      "  - Processed: Rankings_2019.csv (Using column: '2019')\n",
      "  - Processed: Rankings_2020.csv (Using column: '2020')\n",
      "  - Processed: Rankings_2021.csv (Using column: '2021')\n",
      "  - Processed: Rankings_2022.csv (Using column: '2022')\n",
      "  - Processed: Rankings_2023.csv (Using column: '2023')\n",
      "  - Processed: Rankings_2024.csv (Using column: '2024')\n",
      "\n",
      "✅ SUCCESS: 'country_average_fsi_score.csv' has been created.\n",
      "Top 5 Fragile States (Average):\n",
      "         Country  Average_FSI_Total_Score\n",
      "149      Somalia                   112.24\n",
      "152  South Sudan                   111.39\n",
      "177        Yemen                   110.83\n",
      "159        Syria                   109.71\n",
      "45      DR Congo                   108.96\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "COUNTRY_MAPPING = {\n",
    "    'Brunei Darussalam': 'Brunei', 'Cabo Verde': 'Cape Verde', \n",
    "    'Congo Democratic Republic': 'DR Congo', 'Democratic Republic of Congo': 'DR Congo',\n",
    "    'Congo Republic': 'Congo', 'Congo': 'Congo', 'Czech Republic': 'Czechia',\n",
    "    'Kyrgyz Republic': 'Kyrgyzstan', 'Macedonia': 'North Macedonia', \n",
    "    'Slovak Republic': 'Slovakia', 'Timor-Leste': 'East Timor',\n",
    "    'Micronesia': 'Micronesia (country)', 'Türkiye': 'Turkey',\n",
    "    'Israel and West Bank': 'Israel' \n",
    "}\n",
    "\n",
    "EXCLUDED_ENTITIES = {\n",
    "    'Country', 'World', 'Africa', 'Asia', 'Europe', 'North America', \n",
    "    'South America', 'Oceania', 'Rank'\n",
    "}\n",
    "\n",
    "# --- Processing ---\n",
    "fsi_files = glob.glob('Rankings*.csv')\n",
    "all_fsi_data = []\n",
    "\n",
    "print(f\"Found {len(fsi_files)} files. Processing...\")\n",
    "\n",
    "for file_path in fsi_files:\n",
    "    try:\n",
    "        # Read the file with the expected separator and header row (index 1 for FSI files)\n",
    "        # Handle encoding: try utf-8 first, fallback to latin-1\n",
    "        try:\n",
    "             df = pd.read_csv(file_path, sep='\\t', header=1, encoding='utf-16')\n",
    "        except UnicodeDecodeError:\n",
    "             df = pd.read_csv(file_path, sep='\\t', header=1, encoding='latin-1')\n",
    "        \n",
    "        # Identify the Year/Total Score column\n",
    "        year_col = None\n",
    "        # Strategy 1: Look for a column named exactly 'Total'\n",
    "        if 'Total' in df.columns:\n",
    "             year_col = 'Total'\n",
    "        else:\n",
    "            # Strategy 2: Look for a column that is a 4-digit year (e.g., '2020')\n",
    "            for col in df.columns:\n",
    "                if re.match(r'^\\d{4}$', str(col)):\n",
    "                    year_col = col\n",
    "                    break\n",
    "        \n",
    "        if year_col:\n",
    "            # Select and rename\n",
    "            df_clean = df[['Country', year_col]].copy()\n",
    "            df_clean = df_clean.rename(columns={year_col: 'Total_Score'})\n",
    "            \n",
    "            # Basic cleaning\n",
    "            df_clean = df_clean.dropna(subset=['Country'])\n",
    "            df_clean['Country'] = df_clean['Country'].replace(COUNTRY_MAPPING)\n",
    "            \n",
    "            # Ensure Total_Score is numeric\n",
    "            df_clean['Total_Score'] = pd.to_numeric(df_clean['Total_Score'], errors='coerce')\n",
    "            \n",
    "            all_fsi_data.append(df_clean)\n",
    "            print(f\"  - Processed: {file_path} (Using column: '{year_col}')\")\n",
    "        else:\n",
    "            print(f\"  - WARNING: Could not find 'Total' or Year column in {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  - ERROR processing {file_path}: {e}\")\n",
    "\n",
    "# --- Aggregation and Saving ---\n",
    "if all_fsi_data:\n",
    "    df_combined = pd.concat(all_fsi_data, ignore_index=True)\n",
    "    \n",
    "    # Calculate Mean of Total Score for each country\n",
    "    df_averages = df_combined.groupby('Country')['Total_Score'].mean().round(2).reset_index()\n",
    "    df_averages.columns = ['Country', 'Average_FSI_Total_Score']\n",
    "    \n",
    "    # Filter Exclusions\n",
    "    df_averages = df_averages[~df_averages['Country'].isin(EXCLUDED_ENTITIES)]\n",
    "    \n",
    "    # Sort\n",
    "    df_averages = df_averages.sort_values(by='Average_FSI_Total_Score', ascending=False)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_filename = 'country_average_fsi_score.csv'\n",
    "    df_averages.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"\\n✅ SUCCESS: '{output_filename}' has been created.\")\n",
    "    print(\"Top 5 Fragile States (Average):\")\n",
    "    print(df_averages.head())\n",
    "else:\n",
    "    print(\"\\n❌ FAILED: No data could be extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e6d780",
   "metadata": {},
   "source": [
    "#### Combining Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cddedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load All 5 Datasets (Added FSI)\n",
    "counts_df = pd.read_csv('filtered_country_counts.csv')\n",
    "gdp_df = pd.read_csv('country_gdp_averages_imputed.csv')\n",
    "demo_df = pd.read_csv('country_democracy_averages_imputed.csv')\n",
    "power_df = pd.read_csv('country_average_power_index.csv')\n",
    "fsi_df = pd.read_csv('country_average_fsi_score.csv')  # <--- NEW FILE\n",
    "\n",
    "# 2. Clean GDP, Democracy, and FSI Data (Apply Name Corrections)\n",
    "name_corrections = {\n",
    "    \"Turkey\": \"Türkiye\",\n",
    "    \"Russian Federation\": \"Russia\",\n",
    "    \"Egypt, Arab Rep.\": \"Egypt\",\n",
    "    \"Iran, Islamic Rep.\": \"Iran\",\n",
    "    \"Syrian Arab Republic\": \"Syria\",\n",
    "    \"Venezuela, RB\": \"Venezuela\",\n",
    "    \"Yemen, Rep.\": \"Yemen\",\n",
    "    \"Korea, Rep.\": \"South Korea\",\n",
    "    \"Korea, Dem. People's Rep.\": \"North Korea\",\n",
    "    \"Slovak Republic\": \"Slovakia\",\n",
    "    \"Czech Republic\": \"Czechia\",\n",
    "    \"Kyrgyz Republic\": \"Kyrgyzstan\",\n",
    "    \"Lao PDR\": \"Laos\",\n",
    "    \"Congo, Dem. Rep.\": \"DR Congo\",\n",
    "    \"Congo, Rep.\": \"Congo\",\n",
    "    \"Gambia, The\": \"Gambia\",\n",
    "    \"Bahamas, The\": \"Bahamas\",\n",
    "    \"Brunei Darussalam\": \"Brunei\",\n",
    "    \"Cabo Verde\": \"Cape Verde\",\n",
    "    \"Timor-Leste\": \"East Timor\",\n",
    "    \"United States\": \"United States\"\n",
    "}\n",
    "\n",
    "# Apply corrections to GDP and Democracy\n",
    "gdp_df['Country'] = gdp_df['Country'].replace(name_corrections)\n",
    "demo_df['Country'] = demo_df['Country'].replace(name_corrections)\n",
    "demo_df.rename(columns={'Entity': 'Country'}, inplace=True)\n",
    "\n",
    "# Apply corrections to FSI (Specifically Turkey -> Türkiye)\n",
    "fsi_df['Country'] = fsi_df['Country'].replace(name_corrections)\n",
    "\n",
    "# 3. Clean Military Power Data\n",
    "power_df.dropna(subset=['PowerIndex'], inplace=True)\n",
    "power_df['PowerIndex'] = pd.to_numeric(power_df['PowerIndex'], errors='coerce')\n",
    "\n",
    "# Fix Military Name Mismatches\n",
    "military_name_map = {\n",
    "    'Ivory Coast': \"Côte d'Ivoire\",\n",
    "    'Democratic Republic of the Congo': 'DR Congo', \n",
    "    'Republic of the Congo': 'Congo',           \n",
    "    'Beliz': 'Belize',\n",
    "    'Turkey': 'Türkiye' \n",
    "}\n",
    "power_df['Country'] = power_df['Country'].replace(military_name_map)\n",
    "power_df = power_df.groupby('Country')['PowerIndex'].mean().reset_index()\n",
    "\n",
    "\n",
    "# 4. Merge All 5 Datasets Directly\n",
    "# Chain the merges: Frequency -> GDP -> Democracy -> Military -> FSI\n",
    "final_complete_df = counts_df.merge(gdp_df, on='Country', how='inner') \\\n",
    "                             .merge(demo_df, on='Country', how='inner') \\\n",
    "                             .merge(power_df, on='Country', how='inner') \\\n",
    "                             .merge(fsi_df, on='Country', how='left') # Left join for FSI to keep main countries\n",
    "\n",
    "# 5. Impute Missing FSI Scores\n",
    "# (Taiwan, HK, Kosovo are usually missing from FSI but present in others)\n",
    "fsi_imputations = {\n",
    "    'Taiwan': 33.50,\n",
    "    'Hong Kong': 35.00,\n",
    "    'Kosovo': 68.00\n",
    "}\n",
    "\n",
    "for country, score in fsi_imputations.items():\n",
    "    mask = (final_complete_df['Country'] == country) & (final_complete_df['Average_FSI_Total_Score'].isna())\n",
    "    if mask.any():\n",
    "        final_complete_df.loc[mask, 'Average_FSI_Total_Score'] = score\n",
    "\n",
    "# 6. Save the Final Result\n",
    "output_file = 'final_complete_dataset.csv'\n",
    "final_complete_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Merge Complete!\")\n",
    "print(final_complete_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
